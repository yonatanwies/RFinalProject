---

title: '52414, 2022-23: Home Exam'

output:

  html_document: default

  pdf_document: default

date: "July 2nd, 2023"

---





### Submission Instructions (Please read carefully)   



The exam will be submitted **individually** by uploading the solved exam `Rmd` and `html` files to the course `moodle`. 

Please name your files as `52414-HomeExam_2022_23_ID.Rmd` and `52414-HomeExam_2022_23_ID.html` where `ID` is replaced by your ID number (do **not** write your **name** in the file name or in the exam itself).



**Grading:** There are $2$ questions with overall $10$ sub-questions. Each sub-question is worth $10$ points for the exam grade. 



Once you click on the `moodle` link for the home exam, the exam will start and you have three days (72 hours) to complete and submit it. 

The exam will be available from July 2nd, at 9am. The last submission time is July 7th at 5pm. <br>

You may use all course materials, the web and other written materials and R libraries. 

You are NOT allowed to discuss any of the exam questions/materials with other students. 





**Analysis and Presentation of Results:**



Write your answers and explanations in the text of the `Rmd` file (*not* in the `code`). <br>

The text of your answers should be next to the relevant code, plots and tables and refer to them, and not at a separate place at the end. <br>

You need to explain every step of your analysis. When in doubt, a more detailed explanation is better than omitting explanations. 



Give informative titles, axis names and names for each curve/bar in your graphs. 

In some graphs you may need to change the graph limits. If you do so, please include the outlier points you have removed in a separate table.  <br>

Add informative comments explaining your code <br>



Whenever possible, use **objective** and **specific** terms and quantities learned in class, and avoid **subjective** and **general** non-quantified statements. For example: <br>

`Good:` "We see a $2.5$-fold increase in the curve from Jan. 1st to March 1st". <br>

`Bad:` "The curve goes up at the beginning". <br>

`Good:` "The median is $4.7$. We detected five outliers with distance $>3$ standard deviations from the median". <br>

`Bad:` "The five points on the sides seem far from the middle". 



Sometimes `Tables` are the best way to present your results (e.g. when asked for a list of items). Exclude irrelevant

rows/columns. Display clearly items' names in your `Tables`.



Show numbers in plots/tables using standard digits and not scientific display. 

That is: 90000000 and not 9e+06.  

Round numbers to at most 3 digits after the dot - that is, 9.456 and not 9.45581451044



Some questions may require data wrangling and manipulation which you need to 

decide on. The instructions may not specify precisely the exact plot you should use

(for example: `show the distribution of ...`). In such cases, you should decide what and how to show the results. 



When analyzing real data, use your best judgment if you encounter missing values, negative values, NaNs, errors in the data etc. (e.g. excluding them, zeroing negative values..) and mention what you have done in your analysis in such cases. 



Required libraries are called in the `Rmd` file. Install any library missing from your `R` environment. You are allowed to add additional libraries if you want. 

If you do so, **add them at the start of the Rmd file, right below the existing libraries, and explain what libraries you've added, and what is each new library used for**. 



This is an .Rmd file. Copy it with your mouse to create and Rmd file, and edit the file to include your questions.







Good luck!



##############################################################################

```{r, echo = FALSE, results = 'hide', warning=FALSE, message=FALSE}

library(maps)

library(tidyverse)

library(rvest)  # for html

library(uniformly) # for sampling uniformly from the sphere 

library(lubridate)  # for parsing time 

library(e1071) # skewness and kurtosis

library(maditr)

library(data.table)

library(caTools)
####
library(gtools) #used for permutations in Q1
library(ggplot2) # used for plots in Q2
library(dplyr) #used for piped functions %>%
library(reshape2)# used to transpose matrix in Q2
library(RColorBrewer) # to get more distinct colors, for graph in Q2

options(scipen=999)

```





<br/><br/>





## Q1. Random permutations   



![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*C8JOlHLv6F7IMD0vT3yDSg@2x.png)



In this question we study some properties of random **permutations**. A permutation of $n$ elements is a vector $v \in \{1,2,..,n\}^n$ such that $\forall i \neq j$ also $v(i) \neq v(j)$. For example, the vector $v = (3,4,1,5,2)$ is a permutation of $5$ elements. 

The set of permutations on $n$ elements is denoted $S_n$, and has size $|S_n|  = n!$. We consider here radnom sampling of permutation, i.e. a uniform distribution over all $n!$ permutations, where the probability of each permutation being chosen is $\frac{1}{n!}$.





a. (Confused secretary Problem): 

A secretary has $n$ letters and $n$ envelopes with addresses written on them. 

The secretary mixes the letters and puts each letter in a *random* envelope. 

Estimate the probability that *no* letter was sent to the correct address for $n=100$, by running $10,000$ simulations of this process. 
```{r}
sample <- 10000
n <- 100
confused_secretary <- function(n){
  envelopes<-rep(0,times=n)
  correct_assignment<-rep(0,times=n)
  positions <- sample(1:n)  # Randomly select a position
  for(i in 1:n){
  envelopes[i] <- positions[i]
  correct_assignment[i] <- i == positions[i]
  }
  false_count <- sum(!correct_assignment)
  if (false_count == n) {
    return(1) # returns 1 if all the assigments are false
  }
    return(0) # return 0 else
}
outcome <- list()
for (i in 1:sample) { # sample 10,000 times
  result <- confused_secretary(n)
  outcome[[i]] <- result
}
mean(unlist(outcome)) 

```


b. For a permutation $v \in S_n$,  a cycle of length $k$ is a vector of integers $(a_1, a_2, a_3, a_4, .., a_k)$ such that $v(a_1) = a_2, v(a_2) = a_3, .., v(a_{k-1})=a_k$ and $v(a_k) = 1$. For example, for the permutation $v = (3,4,1,5,2)$ we have the cycle $(1,3)$ of length $2$ because $v(1) = 3$ and $v(3) = 1$. We also have the cycle $(2,4,5)$ of length $3$, because $v(2) = 4, v(4) = 5$ and $v(5)=2$. See also another example of the cycles of a permutation in the figure above.  <br>

Let $X_k$ be the number of cycles of length $k$ in a random permutation of length $n$ selected uniformly from $S_n$.  

Estimate $E[X_k]$ for any $k=1,2,..,n$ for $n=100$ and $10,000$ simulations. 

Plot your estimates $\hat{E}[X_k]$ as a function of the cycle length $k$.  <br>

Next, perform a log transformation to the estimates and plot $log(\hat{E}[X_k])$ vs. $log(k)$. 

Fit a simple linear regression model to the log-transformed data add the regression line to the plot. 

Use the fitted model to deduce a formula for the expectation, i.e. a function $g(k)$ such that $E[X_k] = g(k)$. 







```{r}
find_all_cycles <- function(perm) {
  n <- length(perm)
  visited <- logical(n)
  result <- list()
  
  for (i in seq_len(n)) {
    if (visited[i]){
      next
    }
    
    temp <- c(i)
    start <- i
    cur <- perm[i]
    visited[i] <- TRUE
    
    while (cur != start) {
      temp <- c(temp, cur)
      visited[cur] <- TRUE
      cur <- perm[cur]
    }
    
    if (!any(sapply(result, function(x) all(x %in% temp)))) {
      result <- append(result, list(temp))
    }
  }
  
  outcome <- tabulate(lengths(result), nbins = n)
  return(outcome)
}
n <- 100
simulations <- 10000

expectedXk <- numeric(n)

for (i in 1:simulations) {
  perm <- sample(n)
  Xk <- find_all_cycles(perm)
  expectedXk <- expectedXk + Xk
}

expectedXk <- expectedXk / simulations

n <- 100
k <- 1:n

# Plot E^[Xk] as a function of k
plot(k, expectedXk, type = "o", xlab = "Cycle Length (k)", ylab = "Estimated E^[Xk]", main = "Estimates of E^[Xk] for n = 100")

# Perform log transformation
log_expectedXk <- log(expectedXk)
log_k <- log(k)

# Create a data frame with the log-transformed data
data <- data.frame(log_k = log(k), log_expectedXk = log(expectedXk))

# Fit linear regression model
model <- lm(log_expectedXk ~ log_k, data = data)

# Generate predicted values from the model
data$predicted <- predict(model)

# Create the plot using ggplot2
plot <- ggplot(data, aes(x = log_k, y = log_expectedXk)) +
  geom_point() +
  geom_line(aes(y = predicted), color = "red") +
  labs(x = "log(Cycle Length log(k))", y = "log(Estimated log(E^[Xk]))", title = "Log-Log Plot of Estimates for n = 100")

# Display the plot
print(plot)
# the formula is g(k) = 0.7053-1.0037log(k)
```

c. For a random permutation of length $n=100$, Let $p_{12}$ be the probability that the values $1$ and $2$ are in the same cycle.

Estimate this probability using $10,000$ simulations. 

Denote your estimator by $\hat{p}_{12}$. Estimate also the standard deviation of your estimator, 

i.e. provide and estimate $\hat{\sigma}(\hat{p}_{12})$ of $\sigma(\hat{p}_{12})$.

```{r}
n <- 100
simulations <- 10000
count <- 0
p12_values <- numeric(simulations)

for (i in 1:simulations) {
  perm <- sample(n)
  if (1 %in% find_all_cycles(perm) && 2 %in% find_all_cycles(perm)) {
    count <- count + 1
  }
}

p12 <- count / simulations
p12
std_dev <- sqrt(sum((p12_values - p12)^2) / (simulations - 1))
std_dev

```



d. Suppose that Alice and Bob play poker with a deck of only $13$ cards numbered $1,2,..,13$ (all from the same symbol), 

and each of them draw $5$ different cards at random (with $3$ cards remaining in the deck). 

Let $A$ be the event that Alice gets a `straight` hand (i.e. $5$ consecutive numbers on her cards).

Estimate the probability $p_A \equiv P(A)$, this time using $100,000$ simulations. <br>

Let $B$ be the event that Bob gets a `straight` hand.

Suppose now that we know that Alice got a `straight` hand. Let $p_{B|A} = P(B|A)$ be the conditional probability that Bob also got a `straight` hand given this knowledge.  

Estimate this probability using $100,000$ simulations and the method of **rejection sampling**. Is $\hat{p}_{B|A}$ higher or lower than $\hat{p}_A$? Explain <br>

Next, report the fraction of the samples you have rejected.  

Estimate the standard deviations of your two estimators. 

Is $\hat{\sigma}(\hat{p}_{B|A})$ higher or lower than $\hat{\sigma}(\hat{p}_A)$? Explain



```{r}
are_consecutive <- function(numbers) {
  return(all(diff(sort(numbers)) == 1))
}

count_alice<-0
count_bob<-0
simulations<-100000
for(i in 1:simulations){
  ndeck<-1:13
  alice_hand <- sample(ndeck,5)
  bob_hand<-sample(ndeck[-alice_hand],5)
  if(are_consecutive(alice_hand)){
    count_alice = count_alice + 1
  }
  if(are_consecutive(bob_hand)){
    count_bob = count_bob + 1
  }
}
P.a <- round(count_alice/simulations,3)
P.b <- round(count_bob/simulations,3)


nhands <- 5
ndeck <- 1:13

bob_given_alice <- function(ndeck, nhands) {
  alice_hand <- sample(ndeck, nhands)
  bob_hand <- sample(ndeck[-alice_hand], nhands)
  
  alice_has_straight <- all(diff(alice_hand) == 1)
  bob_has_straight <- all(diff(bob_hand) == 1)
  
  if (alice_has_straight) {
    if (bob_has_straight) {
      return(1)
    } else {
      return(0)
    }
  } else {
    return(NA)  # Rejected sample
  }
}

count <- 0
simulations <- 100000
rejected <- 0

for (i in 1:simulations) {
  result <- bob_given_alice(ndeck, nhands)
  if (!is.na(result)) {
    count <- count + result
  } else {
    rejected <- rejected + 1
  }
}

p_b_given_a <- round(count / (simulations - rejected),3)

P.a
P.b

# The probability P(B|A)>P(A), since if Alice shuffled 5 consequitve cards, 
# the remaining cards are definetly in a semi-consequtive order. Meaning, if Alice 
# shuffled (2,3,4,5,6), the remaining cards are (1,7,8,9,10,11,12,13), thus the odds
# of picking consequtive cards increases.


# since P(A) and P(B|A) are binomaly distributed A~Bin(1000000,P(A_hat)=0.07), and 
# B|A=a~Bin(100000,P(B|A)=0.071), the standard deviation can be calculated as npq/n
sd.a <- sqrt(simulations*P.a*(1-P.a))
sd.b.a<-sqrt(simulations*P.ba*(1-P.ba))
sd.a
sd.b.a

# sd.a<sd.b.a since P(B|A)>P(A), and SD is a monotonic increasing function with max(p)=0.5.

```



**Solutions: QU. 1**
```{r}


```


[Write your code and text explanations here]







## Q2. Analysis and Visualization of the COVID-19 Data

![](https://cdn.who.int/media/images/default-source/mca/mca-covid-19/coronavirus-2.tmb-1920v.jpg?sfvrsn=4dba955c_12)



In this question we compare and visualize the trends in terms of numbers of COVID-19 `cases` and `deaths` for different world countries during the pandemic. 



a. Read the COVID-19 dataset file `WHO-COVID-19-global-data.csv` from the [World's Health Organization](https://covid19.who.int/?gclid=Cj0KCQjwudb3BRC9ARIsAEa-vUuF5yzpzQUOyxXJvgsXDE6koerrpqO7go0BPBTylJbYh_fPSaYaMWUaAhNlEALw_wcB) webpage into an $R$ data-frame.

See the link `Data` and then `Data Download` that transfers you to the page with the data and explanations on the data [here](https://covid19.who.int/data). <br>

The data represents the daily number of cases and deaths from COVID19 in different world countries, from the start of the pandemic at $2020$ until the current date <br>

Change the name of the column representing the date to `Date`. Make sure that this column represents only the date and set it to 'date' type. For example, the first element in the 'Date' column should be "2020-01-03". <br>

Show the head and tail of the resulting data-frame. 

```{r}
path <- "https://covid19.who.int/WHO-COVID-19-global-data.csv"
df <- read.csv(path)
colnames(df)[1] <- "Date"
df[,1] <- as.Date(df[,1])
names(df)

head(df)
tail(df)

df$Country[df$Country == "TÃ¼rkiye"] <- "Turkey"
df$Country[df$Country=="Iran (Islamic Republic of)"] <- "Iran"
df$Country[df$Country=="occupied Palestinian territory, including east Jerusalem"] <- "Palestine"
df$Country[df$Country=="Syrian Arab Republic"] <- "Syria"

neighboring_EMRO <- unique(df$Country[which(df$WHO_region=="EMRO")])
neighboring_EMRO<- append(neighboring_EMRO,c("Israel","Cyprus"))
neighboring_EMRO <- neighboring_EMRO[-c(1,2,3,8,10,11,14,17,18,20,21,22)]
cumcases_bycountry_graph<-ggplot(df[df$Country %in% neighboring_EMRO,], aes(x = Date, y = Cumulative_cases, color = Country)) + geom_line() +
  labs(x = "Date", y = "Cumulative Number of Cases", title = "Cumulative COVID-19 Cases by Country") +
  theme_minimal() + theme(legend.position = "left",legend.key.width = unit(0.5, 'cm')) +
  scale_y_continuous(labels = scales::comma)

cumdeaths_bycountry_graph<-ggplot(df[df$Country %in% neighboring_EMRO,], aes(x = Date, y = Cumulative_deaths, color = Country)) + geom_line() +
  labs(x = "Date", y = "Cumulative Number of Deaths", title = "Cumulative COVID-19 Deaths by Country") +
  theme_minimal() + theme(legend.position = "left",legend.key.width = unit(0.5, 'cm')) +
  scale_y_continuous(labels = scales::comma)

cumcases_bycountry_graph
cumdeaths_bycountry_graph
```



b. In this sub-question and the next one, we're interested in plotting the COVID-19 trends in `Israel` and its neighbors. 

Extract as candidate neighbors all countries with `WHO_region = EMRO`. Add `Israel` and other neighbor countries that you notice are missing, and remove far away countries (e.g. `Afghanistan`, `Djibouti`). Use your best judgment in selecting which additional countries to remove, and keep the total number of neighbor countries at below $15$. <br>

Replace long country names with meaningful short names for better readability and graph appearance. 

For example, if `Venezuela (Bolivarian Republic of)` was one of our neighbors, we would have replaced it by `Venezuela`. <br>

Next, plot the `cumulative` number of `cases` as a function of the `Date` for these countries (one plot, a different curve per each country). 

Repeat and show in a different plot the `cumulative` number of `deaths` for each of these countries. 





c. Load the economic dataset available in moodle in the file `economic_data.csv` with demographic and economic information on world countries. 

Merge the two data-frames such that the new data-frame will keep the information in the COVID-19 data-frame, yet will also contain for each row the total population of each country in $2018$. 

Manually rename country names that do not match between the two datasets - you don't have to change all names, but focus on including countries that come up in the analysis of 
(b.) and of the next sub-questions. <br>

Create four new columns, respectively representing the number of *cumulative* `cases` and `deaths` per one million people, and the number of *new* daily `cases` and `deaths` per one million people, for each country and date. <br>

For the same countries used in (b.), plot in two separate figures

the *log-scaled* `cumulative` number of `cases` and `deaths` per million, as a function of the Date. <br>

Which countries suffered the most from the pandemic based on these plots? how did Israel do compared to its neighbors?


```{r}
economic_df<-read.csv("economic_data.csv",stringsAsFactors = FALSE)
economic_df$X2018..YR2018.<-as.numeric(economic_df$X2018..YR2018.)
names(economic_df)[1] <- "Country"
clean_economic <- na.omit(economic_df)


economic_df <- dcast(clean_economic, `Country` ~  `Series.Name`, value.var = "X2018..YR2018.", fun.aggregate = sum)

economic_df$Country[economic_df$Country ==  "Egypt, Arab Rep."] <- "Egypt"
economic_df$Country[economic_df$Country ==  "Syrian Arab Republic"] <- "Syria"
economic_df$Country[economic_df$Country ==  "Iran, Islamic Rep."] <- "Iran"
merged_df<-left_join(df,economic_df,by="Country")
merged_df

merged_df["Cumulative_Cases_per1m"] <- (merged_df$Cumulative_cases*1000000)/merged_df$`Population, total`
merged_df["Cumulative_Deaths_per1m"] <- (merged_df$Cumulative_deaths*1000000)/merged_df$`Population, total`
merged_df["New_Cases_per1m"] <- (merged_df$New_cases*1000000)/merged_df$`Population, total`

merged_df["New_Deaths_per1m"] <- (merged_df$New_deaths*1000000)/merged_df$`Population, total`


color_palette <- brewer.pal(12, "Set3")
# Graph 1: Log-Cumulative COVID-19 Cases by Country
logcumcases_bycountry_graph <- ggplot(merged_df[merged_df$Country %in% neighboring_EMRO,], aes(x = Date, y = log(Cumulative_Cases_per1m), color = Country)) +
  geom_line() +
  labs(x = "Date", y = "Cumulative Number of Cases", title = "Log-Cumulative COVID-19 Cases by Country per 1m") +
  theme_minimal() +
  theme(legend.position = "left", legend.key.width = unit(0.5, "cm")) +
  scale_y_continuous(labels = scales::comma) +
  scale_color_manual(values = color_palette)

# Graph 2: Log-Cumulative COVID-19 Deaths by Country per 1m
logcumdeaths_bycountry_graph <- ggplot(merged_df[merged_df$Country %in% neighboring_EMRO,], aes(x = Date, y = log(Cumulative_Cases_per1m), color = Country)) +
  geom_line() +
  labs(x = "Date", y = "Cumulative Number of Deaths", title = "Log-Cumulative COVID-19 Deaths by Country per 1m") +
  theme_minimal() +
  theme(legend.position = "left", legend.key.width = unit(0.5, "cm")) +
  scale_y_continuous(labels = scales::comma) +
  scale_color_manual(values = color_palette)

# Display the graphs
logcumcases_bycountry_graph
logcumdeaths_bycountry_graph
cumcases_bycountry_graph
cumdeaths_bycountry_graph
# The countries that suffered the most are Israel and Iran Israel is above Egypt in cumulative cases per 1m - the most cases reported in Israel compared to Egypt is 543597.8 vs 93062.49 respectively. That is 5.84 times more _reported_ cases in Israel than in Iran It is however important to note that Israel is more developed than Iran, meaning the reported number can be more trustworthy.

max(merged_df$Cumulative_Cases_per1m[which(merged_df$Country=="Israel")])/
  max(merged_df$Cumulative_Cases_per1m[which(merged_df$Country=="Iran")])

specific_country_deaths <- merged_df %>%
  filter(Country %in% neighboring_EMRO) %>%
  group_by(Country) %>%
  summarize(Max_Cumulative_Deaths = max(Cumulative_deaths)) %>%
  arrange(desc(Max_Cumulative_Deaths)) %>%
  distinct()

specific_country_deaths


# with regards to absloute numbers, Iran is the great "winner" here - with 146297 max deaths. That number is objectivly larger than its successor, Iraq, which has 25375 reported deaths. That is a 120922 difference, and a 576% scale difference.It is also worth to mention that Iraq's and Iran's communication with the western world is less trustworthy than Israel's or Jordan's. We can assume the numbers are even greater than the reported. 
```

d. One measure of the healthcare system strength in a country is the ratio between the number of deaths and the number of cases (with the caveats that this number is affected by other things like

the population age-structure, the fact that testing and diagnosing cases are different between countries etc.). <br> 

Extract for *all* countries the latest reported cumulative number of `cases per million` and `deaths per million` per country (it is recommended to create a new data-frame with one row per country), and make a scatter-plot comparing the two shown on a `log-scale`.  

Fit a linear regression line to the log-scaled data. <br>

Define the `fatality rate` as the ratio between the latest reported cumulative numbers of `deaths` and `cases`, i.e. an estimate of the probability that an infected individual died form the disease. Display the distribution of `fatality rate` across countries using a plotting method of your choice. Describe the distribution: what is the mean/median? is it symmetric? skewed? are there outlier countries? which ones?
```{r}
# Extract the latest reported cumulative cases and deaths per million
latest_cases <- aggregate(log(Cumulative_Cases_per1m) ~ Country, data = merged_df, FUN = function(x) tail(x, 1))
latest_deaths <- aggregate(log(Cumulative_Deaths_per1m) ~ Country, data = merged_df, FUN = function(x) tail(x, 1))

# Merge the two data frames
latest_data <- merge(latest_cases, latest_deaths, by = "Country")
latest_data<- latest_data[-c(30,54,174),] #removed Erithrea and Turkmenistan, that had NaN values. Burundi had cumulative deaths per 1m < 1, which pointed as an outlier on the graph. According to Wikipedia, "Burundi is the poorest country in the world as per GDP per capita, and is one of the least developed countries, facing widespread poverty, corruption, instability, authoritarianism, and illiteracy." It is safe to presume the reported numbers are inaccurate, and not to be compare to.

colnames(latest_data) <- c("Country", "Cumulative_Cases_per1m", "Cumulative_Deaths_per1m")

# Create the scatter plot on a log scale
logdeaths_vs_logcases <- ggplot(latest_data, aes(x = log(Cumulative_Cases_per1m), y = log(Cumulative_Deaths_per1m))) +
  geom_point() +
  labs(x = "Log Cumulative Cases per million", y = "Log Cumulative Deaths per million", title = "COVID-19 Cases vs Deaths per million") +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal() 
  

model <- lm(log(Cumulative_Deaths_per1m) ~ log(Cumulative_Cases_per1m), data = latest_data)

logdeaths_vs_logcases + geom_abline(intercept = coef(model)[1], slope = coef(model)[2], color = "blue")



fatality_rate <- latest_data$Cumulative_Deaths / latest_data$Cumulative_Cases

# Create a data frame with fatality rate and country
fatality_data <- data.frame(Country = latest_data$Country, Fatality_Rate = fatality_rate)

# Plotting the histogram
ggplot(fatality_data, aes(x = Fatality_Rate)) +
  geom_histogram(binwidth = 0.02, fill = "steelblue", color = "white") +
  labs(x = "Fatality Rate", y = "Count", title = "Distribution of Fatality Rate") +
  theme_minimal()

ggplot(fatality_data, aes(x = "", y = Fatality_Rate)) +
  geom_violin(trim = FALSE, fill = "lightblue") +
  labs(x = "", y = "Fatality Rate", title = "Distribution of Fatality Rate across Countries") +
  theme_minimal()

mean_fatality <- round(mean(fatality_data$Fatality_Rate),3)
median_fatality <- round(median(fatality_data$Fatality_Rate),3)

#according to common agreement, the outliers are such that they are > 2 standard deviations from the mean. 
outliers <- fatality_data[fatality_data$Fatality_Rate > (mean_fatality + 2 * sd(fatality_data$Fatality_Rate)), "Country"]

# The only outlier is my filtered data, is Peru.
above_mean <- sum(fatality_data$Fatality_Rate > mean_fatality)
proportion_above_mean <- round(above_mean / nrow(fatality_data),3)
skewness(fatality_data$Fatality_Rate)
#The distribution is not symmetric. According to the code above, we can see that the proportion of observations above the mean is 0.575
#Raw data:
#Mean: 0.565
#Median: 0.581
#Skewness: -0.75 
#Since the Median is greater than the Mean, we can define the graph as moderately  positively skewed.
```




e. Find the countries suffering the highest number of deaths by COVID-19, i.e. those with $>200,000$ cumulative number of `deaths`.

For these countries, plot the `smoothed` number of `new` daily cases. 

You can use the `geom_smooth` function. <br>

Describe the different qualitative behaviors of the curves of the different countries. 

Which countries were hit earliest/latest by the pandemic? 

Is there a different in the number of waves suffered by each country? 


```{r}
most_suffered<- subset(df, Cumulative_deaths>200000) 

ggplot(most_suffered, aes(x = Date, y = New_cases, color = Country)) +
  geom_smooth() +
  labs(title = "Smoothed New Daily Cases for Countries with >200,000 Cumulative Deaths",
       x = "Date",
       y = "New Cases") +
  theme_minimal() + scale_y_continuous(labels = scales::comma_format())

# 
# The curves of different countries exhibit distinct qualitative behaviors. One notable example is the curves of the United States (pink) and India (light brown). The US curve shows two significant peaks, indicating waves of new cases, with one day reaching nearly 300,000 cases. The country was also among the first to surpass 200,000 deaths, which occurred in the middle of 2020. In contrast, India reached 200,000 deaths in the middle of 2021 and experienced a substantial decline in cases afterward, with the number of daily cases dropping from over 300,000 to a significantly lower level. Since then, India has had one major wave with over 100,000 cases.
# 
# Mexico (dark green) displays a relatively smooth curve with a smaller maximum peak and a flatter line in the middle. Other countries in the group exhibit different curve patterns, with varying times of surpassing 200,000 deaths.
# 
# Regarding the timing of the pandemic, the United States was among the earliest countries hit, being one of the first to surpass 200,000 deaths. On the other hand, the United Kingdom experienced this milestone later than the other countries in the group.
# 
# Each country shows a different number of waves in its curve, with no two curves resembling each other. It is also worth considering that the response measures and restrictions implemented by each country can influence the shape and intensity of the waves. While some countries may have taken strict measures and imposed restrictions, others, like Mexico, may have had different approaches and exhibited distinct patterns in their curves. The introduction of vaccines in late 2021 has also played a role, leading to declining curves in some countries.
```




f. Plot the new  number of `cases` and `death` as a function of the date in each of the six `WHO_regions`: `EMRO`,  `EURO`,  `AFRO`,  `WPRO`,  `AMRO`,  `SEARO` (filter `Others`), in two separate plots (each region in a different color). Describe the results. <br>

Create a new column representing `GDP per capita` for each country. Then, plot the empirical CDF of the `GDP per capita` and the 

percent of population above $65$ (`pop65`) in each of the six `WHO_regions`, in two separate plots (each region in a different color). Describe the results.

```{r}
regions <- c(unique(merged_df$WHO_region))

# Plot for new cases by WHO region
ggplot(merged_df, aes(x = Date, y = New_cases, color = WHO_region)) +
  geom_line() +
  labs(x = "Date", y = "New Cases", title = "New COVID-19 Cases by WHO Region") +
  scale_color_discrete(name = "WHO Region") +
  theme_minimal()

# Plot for new deaths by WHO region
ggplot(merged_df, aes(x = Date, y = New_deaths, color = WHO_region)) +
  geom_line() +
  labs(x = "Date", y = "New Deaths", title = "New COVID-19 Deaths by WHO Region") +
  scale_color_discrete(name = "WHO Region") +
  theme_minimal()

#######DESCRIBE THE RESULTS

names(merged_df)[13]<-"pop65"

merged_df$GDP_per_capita <- merged_df$`GDP, PPP (current international $)` / merged_df$`Population ages 65 and above (% of total population)`


ggplot(merged_df, aes(x = GDP_per_capita, color = WHO_region)) +
  stat_ecdf(geom = "step") +
  labs(x = "GDP per Capita", y = "Empirical CDF", title = "Empirical CDF of GDP per Capita by WHO Region") +
  scale_color_discrete(name = "WHO Region") +
  theme_minimal()

# Plot percentage of population above 65 (pop65) by WHO region
ggplot(merged_df, aes(x = pop65, color = WHO_region)) +
  stat_ecdf(geom = "step") +
  labs(x = "Percentage of Population Above 65", y = "Empirical CDF", title = "Empirical CDF of Pop65 by WHO Region") +
  scale_color_discrete(name = "WHO Region") +
  theme_minimal()


```







**Solutions: QU. 2**



[Write your code and text explanations here]

